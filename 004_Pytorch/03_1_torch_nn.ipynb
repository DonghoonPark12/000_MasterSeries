{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASS torch.nn.Module(*args, **kwargs)\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer\n",
    "- 모든 뉴럴 네트워크 모듈의 베이스 클래스이다.\n",
    "- 구현자의 모델은 모두 본 클래스의 자식 클래스이다.\n",
    "- 모듈은 다른 모듈을 포함(contain)할 수 있고, 이 들을 트리 구조로 중첩 시킬수 있다. 서브 모듈을 attributes 처럼 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 서브 모듈(위의 예제에서는 nn.Conv2d())도 등록이 되며 to() 를 이용하여 호출할 때 해당 매개변수도 변환된다.\n",
    "- 상위 클래스(nn.Module)에 대한 호출 (super().__init__())은 하위 클래스 생성 전에 이뤄저야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수  \n",
    "training(bool)\n",
    "- 해당 모듈 학습 여부를 Boolean으로 나타낸다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add_module(name, module)\n",
    "- 현재 모듈에 자식 모듈을 삽입한다.\n",
    "- 모듈은 name을 통해 속성처럼 접근할 수 있다.\n",
    "  \n",
    "apply(fn)\n",
    "- fn를 자신(self)를 포함한 모든 서브 모델에 재귀적으로 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True) <-----\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True) <-----\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    print(m)\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.fill_(1.0)\n",
    "        print(m.weight, '<-----')\n",
    "net = nn.Sequential(nn.Linear(2,2), nn.Linear(2,2))\n",
    "print(net)\n",
    "print('\\n')\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `buffers(recurse=True)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `named_parameters(prefix='', recurse=True, remove_duplicate=True)`\n",
    "- 모듈 파라미터의 이터레이터를 리턴한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `modules()`\n",
    "- 네트워크 상의 모든 모듈의 이터레이터를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "0 -> Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "1 -> Linear(in_features=2, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "l = nn.Linear(2, 2)\n",
    "net = nn.Sequential(l, l)\n",
    "print(net)\n",
    "\n",
    "print('-' * 50)\n",
    "\n",
    "for idx, m in enumerate(net.modules()):\n",
    "    print(idx, '->', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `register_buffer(name, tensor, persistent=True)`\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. 모듈과 파라미터 차이??\n",
    "- 모듈은 모델을 구성하는 클래스 집합 인 것으로 보이고,\n",
    "- 파라미터는 학습 가능한 파라미터를 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable ResNet object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\00_PILSA\\000_MasterSeries\\004_Pytorch\\torch_nn.ipynb 셀 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/00_PILSA/000_MasterSeries/004_Pytorch/torch_nn.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, m \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mmodules():\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/00_PILSA/000_MasterSeries/004_Pytorch/torch_nn.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/00_PILSA/000_MasterSeries/004_Pytorch/torch_nn.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable ResNet object"
     ]
    }
   ],
   "source": [
    "for idx, m in model.modules(): # named_modules()로 호출하지 않으니 불러 오지 못한다??\n",
    "    print(m)\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, m in model.named_modules():\n",
    "    print(m)\n",
    "    print('=' * 50)\n",
    "    for param in m.parameters():\n",
    "        print(type(param), param.size())\n",
    "    print('=' * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('mm3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d69b847d396095f32f676329057412de0235e6809d7fbe768ce2e81f9c069d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
