{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.cuda.Event(enable_timing=False, blocking=False, interprocess=False)`\n",
    "- CUDA 이벤트를 감싸는 래퍼이다\n",
    "- CUDA 이벤트는 장치의 진행 사항을 모니터링하고, CUDA 스트림을 동기화하는데 사용할 수 있는 동기화 마커이다.\n",
    "- 기본 CUDA 이벤트는 `이벤트가 처음 기록되거나`, `다른 프로세스로 내보내질 때` 지연 초기화 된다(lazily initialized).\n",
    "- 생성 후에는 동일한 장치의 스트림만 이벤트를 녹화할 수 있습니다. 그러나 모든 장치의 스트림은 이벤트를 기다릴 수 있다(?).\n",
    "  \n",
    "(이하 디폴트 False)\n",
    "- enable_timing (bool, optional): 이벤트가 시간을 측정해야 하는지 나타낸다.\n",
    "- blocking (bool, optional): True 면 wait()가 블로킹 된다.\n",
    "- interprocess (bool, optional): True 면 이벤트는 프로세스 간에 공유될 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pytorch 에서 CUDA 호출이 비동기식이기 때문에 타이머를 시작 또는 중지 하기 전에 torch.cuda.synchronize() 를 통해 코드를 동기화 시켜주어야 한다. \n",
    "출처: https://eehoeskrap.tistory.com/462 [Enough is not enough:티스토리]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `torch.backends.cudnn.benchmark = True` 의미\n",
    "- 모델이 변경되지 않고, 입력 크기가 동일하게 유지되는 경우 torch.backends.cudnn.benchmark = True 설정하면 이점을 얻을 수 있다.\n",
    "- 만약, 모델이 변경되는 경우 (e.g. 특정 조건이 충족될 경우만 \"Activated\" 되는 레이어가 있거나, 루프 안에 있는 레이어가 경우에 따라 다른 횟수로 반복하는 경우) torch.backends.cudnn.benchmark = True는 문제가 될 수 있다.\n",
    "- True인 경우 cnDNN이 여러 컨볼루션 알고리즘을 벤치마킹하고, 가장 빠른 알고리즘을 선택하도록 한다.\n",
    "- https://stackoverflow.com/questions/58961768/set-torch-backends-cudnn-benchmark-true-or-not\n",
    "- https://seobway.tistory.com/entry/torchbackendscudnnbenchmarktrue\n",
    "- https://pytorch.org/docs/stable/backends.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
