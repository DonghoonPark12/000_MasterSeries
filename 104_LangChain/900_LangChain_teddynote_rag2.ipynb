{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain RAG 파헤치기: 문서 기반 QA 시스템 설계 방법 - 심화편"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. 도큐먼트 로더(document_loader): RAW DATA 로부터 데이터 읽기\n",
    "- 2. 문서 분할(splitter): 문서를 규칙에 의하여 Chunk 로 분할\n",
    "- 3. Embedding: 다양한 임베딩 알고리즘\n",
    "- 4. VectorStore: 벡터DB 에 데이터 저장\n",
    "- 5. Embedding: 데이터 저장시 사용할 임베더 선택\n",
    "- 6. Retriever: 사용자 쿼리에 따른 데이터 검색\n",
    "- 7. 프롬프트(Prompt): LangSmith 의 프롬프트 로드\n",
    "- 8. 모델(LLM): OpenAI, HuggingFace 오픈소스 모델\n",
    "- 9. 체인 생성: 체인 생성 후 쿼리(query)\n",
    "- 10. RAG 템플릿 실험: 실제 문서를 활용한 실험 결과 공유 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "#openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# 디버깅을 위한 프로젝트명을 기입합니다.\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"RAG TUTORIAL\"\n",
    "\n",
    "# tracing 을 위해서는 아래 코드의 주석을 해제하고 실행합니다.\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = true\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 도큐먼트 로더(document_loader): RAW DATA 로부터 데이터 읽기\n",
    "- 참조: https://python.langchain.com/docs/integrations/document_loaders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹페이지\n",
    "# 뉴스기사의 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 23\n",
      "\n",
      "[페이지내용]\n",
      "SPRi AI Brief |  \n",
      "2023-12 월호\n",
      "8코히어 , 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기 ’ 플랫폼을 출시\n",
      "n대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능KEY Contents\n",
      "£데이터 출처 탐색기 , 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "nAI 기업 코히어 (Cohere) 가 매사추세츠 공과⼤(MIT), 하버드 ⼤ 로스쿨 , 카네기멜론 ⼤ 등 12개 기관과  \n",
      "함께 2023 년 10월 25일 ‘데이터 출처 탐색기 (Data Provenance Explorer)’ 플랫폼을 공개\n",
      "∙AI 모델 훈련에 사용되는 데이터셋의 불분명한 출처로 인해 데이터 투명성이 확보되지 않아 다양한 \n",
      "법적·윤리적 문제가 발생\n",
      "∙이에 연구진은 가장 널리 사용되는 2,000 여 개의 미세조정 데이터셋을 감사 및 추적하여 데이터셋에 \n",
      "원본 데이터소스에 대한 태그, 재라이선스 (Relicensing) 상태, 작성자 , 기타 데이터 속성을 지정하고 \n",
      "이러한 정보에 접근할 수 있는 플랫폼을 출시\n",
      "∙대화형 플랫폼 형태의 데이터 출처 탐색기를 통해 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 , \n",
      "주요 데이터셋의 구성과 데이터 계보도 추적 가능\n",
      "n연구진은 오픈소스 데이터셋에 대한 광범위한 감사를 통해 데이터 투명성에 영향을 미치는 주요 \n",
      "요인을  발견\n",
      "∙깃허브 (GitHub), 페이퍼위드코드 (Papers with Code) 와 같은 크라우드소싱 플랫폼에서 수집한 \n",
      "데이터로 훈련된 오픈소스 LLM에서는 데이터 라이선스의 누락 비율이 72~83% 에 달함 \n",
      "∙또한 크라우드소싱 플랫폼이 할당한 라이선스는 데이터셋 원저작자의 의도보다 더 광범위한 사용을 \n",
      "허용한 경우가 상당수\n",
      "∙데이터 생태계 분석 결과, 부정확하거나 모호한 라이선스 문서화 등 데이터 출처 입증과 관련된 관행 \n",
      "전반에서 구조적 문제가 드러남\n",
      "n연구진은 데이터 출처 탐색기만으로는 해결이 어려운 법적 이슈도 존재한다며 일관된 법적 프레임\n",
      "워크의 필요성을 제기\n",
      "∙일례로 데이터를 수집한 지역, 모델 훈련 지역, 모델 배포 지역마다 규제가 다르면 어떤 법률을 \n",
      "적용해야 하는지 실무자의 판단이 어려울 수 있으며 , 서로 다른 라이선스를 적용받는 개별 데이터셋을 \n",
      "하나로 통합해 사용하는 경우에도 각각의 라이선스 조건 준수에 어려움이 발생\n",
      "☞ 출처 : Cohere, Data Provenance Explorer Launches to Tackle Data Transparency Crisis, 2023.10.25.\n",
      "\n",
      "[metadata]\n",
      "{'source': './SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDF\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"./SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 페이지 별 문서 로드\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "# CSV 파일 로드\n",
    "loader = CSVLoader(file_path=\"data/titanic.csv\")\n",
    "docs = loader.load()\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[10].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. 문서 분할(splitter): 문서를 규칙에 의하여 Chunk 로 분할\n",
    "- 3. Embedding: 다양한 임베딩 알고리즘\n",
    "- 4. VectorStore: 벡터DB 에 데이터 저장\n",
    "- 5. Embedding: 데이터 저장시 사용할 임베더 선택\n",
    "- 6. Retriever: 사용자 쿼리에 따른 데이터 검색\n",
    "- 7. 프롬프트(Prompt): LangSmith 의 프롬프트 로드\n",
    "- 8. 모델(LLM): OpenAI, HuggingFace 오픈소스 모델\n",
    "- 9. 체인 생성: 체인 생성 후 쿼리(query)\n",
    "- 10. RAG 템플릿 실험: 실제 문서를 활용한 실험 결과 공유 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <이전 단계에서 수행 했던 것>\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "# 뉴스기사 내용을 로드하고, 청크로 나누고, 인덱싱합니다.\n",
    "url = \"https://n.news.naver.com/article/437/0000378416\"\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# 단계 4: 검색(Search)\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 5: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 단계 6: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 단계 7: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"부영그룹의 출산 장려 정책에 대해 설명해주세요\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"URL: {url}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchWin_rev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
