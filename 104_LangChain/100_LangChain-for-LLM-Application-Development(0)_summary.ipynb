{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Models, Prompts and Output Parsers\n",
    "\n",
    "<목차>\n",
    "- 1. Chat API : OpenAI\n",
    "  - Direct API calls to OpenAI\n",
    "- 2. Chat API : LangChain \n",
    "  - API calls through LangChain\n",
    "    - chat = ChatOpenAI()\n",
    "    - prompt_template = ChatPromptTemplate.from_template()\n",
    "    - prompt_template.format_messages()\n",
    "- 3. Output parsers\n",
    "  - langchain.output_parsers.ResponseSchema\n",
    "  - langchain.output_parsers.StructuredOutputParser\n",
    "\n",
    "Outline\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "<요약>\n",
    "* langchain.chains.ConversationChain(llm, memory, verbose)\n",
    "    - .predict(input=\"\")\n",
    "* langchain.memory.ConversationBufferMemory(): 메시지를 저장하고, 변수 안에서 메시지를 추출\n",
    "* langchain.memory.ConversationBufferWindowMemory(k) : k로 저장 대화 갯수 조정 가능\n",
    "* langchain.memory.ConversationTokenBufferMemory() : interactions 수 대신 토큰 길이를 사용하여 interactions을 플러시 할 시기를 결정\n",
    "* langchain.memory.ConversationSummaryMemory()\n",
    "    - .buffer : 나눈 대화가 저장\n",
    "    - .load_memory_variables({}) : json으로 출력\n",
    "    - .save_context() : save_context로 대화를 직접 넣을 수 있다. \n",
    "        - ChatMessageHistory()와 .from_messages 를 이용할 수도 있지만, .save_context()가 더 선호"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains in LangChain\n",
    "\n",
    "<요약>\n",
    "* LLMChain\n",
    "* Sequential Chains\n",
    "  * langchain.chains.SimpleSequentialChain\n",
    "  * langchain.chains.SequentialChain\n",
    "* Router Chain\n",
    "  * langchain.chains.router.MultiPromptChain\n",
    "  * langchain.chains.router.llm_router.LLMRouterChain, \n",
    "  * langchain.chains.router.llm_router.RouterOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Q&A over Documents\n",
    "\n",
    "An example might be a tool that would allow you to query a product catalog for items of interest.\n",
    "\n",
    "<요약>  \n",
    "- (1) VectorstoreIndexCreator에서 임베딩 기능 없이 query로 직접 검색  \n",
    "    - index = VectorstoreIndexCreator(vectorstore_cls = DocArrayInMemorySearch).from_loaders([loader])  \n",
    "    - response = index.query(query, llm = llm_replacement_model)\n",
    "- (2) Document과 Query를 임베딩하여 유사도 기반 검색\n",
    "    - db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    - docs = db.similarity_search(query)\n",
    "- (3) Retriever를 이용하는 방법\n",
    "    - qa_stuff = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, verbose=True)\n",
    "    - response = qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Evaluation\n",
    "<목차>\n",
    "- (1) Q&A App 생성\n",
    "  - (1-1) 하드코딩 정답 생성\n",
    "    - RetrievalQA.from_chain_type\n",
    "    - example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())\n",
    "    - new_examples = example_gen_chain.apply_and_parse()\n",
    "    - qa.run(examples[0][\"query\"])\n",
    "- 2. 수동 평가\n",
    "- 3. LLM-assisted 평가\n",
    "    - eval_chain = QAEvalChain.from_llm(llm)\n",
    "    - eval_chain.evaluate(examples, predictions)\n",
    "\n",
    "\n",
    "Outline:\n",
    "* Example generation\n",
    "* Manual evaluation (and debuging)\n",
    "* LLM-assisted evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Agents\n",
    "\n",
    "<목차>\n",
    "- 1. 빌트인 랭체인 도구\n",
    "- 2. 파이썬 에이전트\n",
    "  - 2-1. 체인의 상세한 출력 확인\n",
    "- 3. 커스텀 도구 정의\n",
    "\n",
    "Outline:\n",
    "* Using built in LangChain tools: DuckDuckGo search and Wikipedia\n",
    "* Defining your own tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
