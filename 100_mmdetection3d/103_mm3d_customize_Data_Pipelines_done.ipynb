{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOMIZE DATA PIPELINES\n",
    "#### Design of Data pipelines\n",
    "- 다수의 워커(프로세서)로 데이터를 로딩 시 Dataset, DataLoader를 사용한다.\n",
    "- Dataset은 모델의 forward 메소드 실행에 필요한 Arguments에 대응하는 items을 가지는 딕셔너리를 리턴한다.\n",
    "  (Dataset의 리턴 값은 모델 forward 메소드의 인자를 키 값으로 가지는 딕셔너리이다)\n",
    "- Object Detection의 데이터는 모두 동일한 사이즈가 아닐 것이기 때문에, DataContainter 타입을 제안하여 각기 다른 사이즈의 데이터를 수집하고 분산 시키는데 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset 은 어노테이션을 어떻게 처리할 것인지를 정의하고, data pipeline은 data dict를 준비하기 위한 모든 스텝을 정의한다.\n",
    "- 데이터 파이프라인은 연산의 연속으로 구성되는데, 각 연산은 (데이터) 딕셔너리를 입력으로 받아 (다음 Transform 입력을 위해) 딕셔너리를 넘겨준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://mmdetection3d.readthedocs.io/en/latest/_images/data_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = [\n",
    "    dict(\n",
    "        type='LoadPointsFromFile',\n",
    "        load_dim=5,\n",
    "        use_dim=5,\n",
    "        backend_args=backend_args\n",
    "    ),\n",
    "    dict(\n",
    "        type='LoadPointsFromMultiSweeps',\n",
    "        sweeps_num=10,\n",
    "        backend_args=backend_args\n",
    "    ),\n",
    "    dict(\n",
    "        type='LoadAnnotations3D', \n",
    "        with_bbox_3d=True, \n",
    "        with_label_3d=True\n",
    "    ),\n",
    "    dict(\n",
    "        type='GlobalRotScaleTrans',\n",
    "        rot_range=[-0.3925, 0.3925],\n",
    "        scale_ratio_range=[0.95, 1.05],\n",
    "        translation_std=[0, 0, 0]\n",
    "    ),\n",
    "    dict(type='RandomFlip3D', flip_ratio_bev_horizontal=0.5),\n",
    "    dict(type='PointsRangeFilter', point_cloud_range=point_cloud_range),\n",
    "    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n",
    "    dict(type='ObjectNameFilter', classes=class_names),\n",
    "    dict(type='PointShuffle'),\n",
    "    dict(type='DefaultFormatBundle3D', class_names=class_names),\n",
    "    dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])\n",
    "]\n",
    "\n",
    "test_pipeline = [\n",
    "    dict(\n",
    "        type='LoadPointsFromFile',\n",
    "        load_dim=5,\n",
    "        use_dim=5,\n",
    "        backend_args=backend_args),\n",
    "    dict(\n",
    "        type='LoadPointsFromMultiSweeps',\n",
    "        sweeps_num=10,\n",
    "        backend_args=backend_args),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1333, 800),\n",
    "        pts_scale_ratio=1.0,\n",
    "        flip=False,\n",
    "        pcd_horizontal_flip=False,\n",
    "        pcd_vertical_flip=False,\n",
    "        transforms=[\n",
    "            dict(\n",
    "                type='GlobalRotScaleTrans',\n",
    "                rot_range=[0, 0],\n",
    "                scale_ratio_range=[1., 1.],\n",
    "                translation_std=[0, 0, 0]),\n",
    "            dict(type='RandomFlip3D'),\n",
    "            dict(\n",
    "                type='PointsRangeFilter', point_cloud_range=point_cloud_range),\n",
    "            dict(\n",
    "                type='DefaultFormatBundle3D',\n",
    "                class_names=class_names,\n",
    "                with_label=False),\n",
    "            dict(type='Collect3D', keys=['points'])\n",
    "        ]\n",
    "    )\n",
    "]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoading  \n",
    "- LoadPointsFromFile -> add: points  \n",
    "- LoadPointsFromMultiSweeps -> update: points  \n",
    "- LoadAnnotations3D --> add: gt_bboxes_3d, gt_labels_3d, gt_bboxes, gt_labels, pts_instance_mask, pts_semantic_mask, bbox3d_fields, pts_mask_fields, pts_seg_fields  \n",
    "  \n",
    "Pre-processing  \n",
    "- GlobalRotScaleTrans  \n",
    "  -> add:pcd_trans, pcd_rotation, pcd_scale_factor   \n",
    "  -> update: points, *bbox3d_fields  \n",
    "- RandomFlip3D  \n",
    "  -> add: flip, pcd_horizontal_flip, pcd_vertical_flip  \n",
    "  -> update: points, *bbox3d_fields  \n",
    "- PointsRangeFilter -> update: points  \n",
    "- ObjectRangeFilter -> update: gt_bboxes_3d, gt_labels_3d  \n",
    "- ObjectNameFilter -> update: gt_bboxes_3d, gt_labels_3d  \n",
    "- PointShuffle -> update: points  \n",
    "- PointsRangeFilter -> update: points  \n",
    "  \n",
    "Formatting\n",
    "- DefaultFormatBundle3D  \n",
    " -> update: points, gt_bboxes_3d, gt_labels_3d, gt_bboxes, gt_labels  \n",
    "- Collect3D  \n",
    "  -> add: img_meta (the keys of img_meta is specified by meta_keys)  \n",
    "  -> remove: all other keys except for those specified by keys  \n",
    "  \n",
    "Test Time Augmentation\n",
    "- MultiScaleFlipAug\n",
    "  -> scale, pcd_scale_factor, flip, flip_direction, pcd_horizontal_flip, pcd_vertical_flip\n",
    "\n",
    "(해당 부분이 중요한 부분이라면, 나중에 표로 정리해도 좋을 듯 하다. Augmentation 옵션 별(row) / add, update 여부(column) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend and use custom pipelines\n",
    "1. 가칭 my_pipeline.py 은 Data Pipeline과 마찬가지로 dict을 입, 출력으로 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import PIPELINES\n",
    "\n",
    "@PIPELINES.register_module()\n",
    "class MyTransform:\n",
    "    def __call__(self, results):\n",
    "        results['dummy'] = True\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 새로운 클래스를 임포트 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = [\n",
    "    dict(\n",
    "        type='LoadPointsFromFile',\n",
    "        load_dim=5,\n",
    "        use_dim=5,\n",
    "        backend_args=backend_args\n",
    "    ),\n",
    "    dict(\n",
    "        type='LoadPointsFromMultiSweeps',\n",
    "        sweeps_num=10,\n",
    "        backend_args=backend_args\n",
    "    ),\n",
    "    dict(\n",
    "        type='LoadAnnotations3D', \n",
    "        with_bbox_3d=True, \n",
    "        with_label_3d=True\n",
    "    ),\n",
    "    dict(\n",
    "        type='GlobalRotScaleTrans',\n",
    "        rot_range=[-0.3925, 0.3925],\n",
    "        scale_ratio_range=[0.95, 1.05],\n",
    "        translation_std=[0, 0, 0]\n",
    "    ),\n",
    "    dict(type='RandomFlip3D', flip_ratio_bev_horizontal=0.5),\n",
    "    dict(type='PointsRangeFilter', point_cloud_range=point_cloud_range),\n",
    "    dict(type='ObjectRangeFilter', point_cloud_range=point_cloud_range),\n",
    "    dict(type='ObjectNameFilter', classes=class_names),\n",
    "    dict(type='MyTransform'), # <--------------------------------------------------- Here!\n",
    "    dict(type='PointShuffle'),\n",
    "    dict(type='DefaultFormatBundle3D', class_names=class_names),\n",
    "    dict(type='Collect3D', keys=['points', 'gt_bboxes_3d', 'gt_labels_3d'])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ DataContainer\n",
    "- 텐서는 collate function에 쌓이게(stacked) 되고, 동일 차원의 값으로 슬라이스 한다. \n",
    "- 이때 모든 텐서는 동일사이즈이며, 타입이 (numpy array or Tensor)로 제한되게 된다.\n",
    "- 이 문제를 해결하기 위해 DataContainer and MMDataParallel 을 도입하였다.\n",
    "\n",
    "https://mmdetection3d.readthedocs.io/en/latest/_images/data_pipeline.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataContainer:\n",
    "    \"\"\"A container for any type of objects.\n",
    "\n",
    "    Typically tensors will be stacked in the collate function and sliced along\n",
    "    some dimension in the scatter function. This behavior has some limitations.\n",
    "    1. All tensors have to be the same size.\n",
    "    2. Types are limited (numpy array or Tensor).\n",
    "\n",
    "    We design `DataContainer` and `MMDataParallel` to overcome these\n",
    "    limitations. The behavior can be either of the following.\n",
    "\n",
    "    - copy to GPU, pad all tensors to the same size and stack them\n",
    "    - copy to GPU without stacking\n",
    "    - leave the objects as is and pass it to the model\n",
    "    - pad_dims specifies the number of last few dimensions to do padding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                data: Union[torch.Tensor, np.ndarray],\n",
    "                stack: bool = False,\n",
    "                padding_value: int = 0,\n",
    "                cpu_only: bool = False,\n",
    "                pad_dims: int = 2):\n",
    "        self._data = data\n",
    "        self._cpu_only = cpu_only\n",
    "        self._stack = stack\n",
    "        self._padding_value = padding_value\n",
    "        assert pad_dims in [None, 1, 2, 3]\n",
    "        self._pad_dims = pad_dims\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('torchWin_rev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcfd0bbc3e25ae79d1f134c08b87e3777d49169aec2e55e1b5fb8249822c085d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
