{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN WITH CUSTOMIZED DATASETS\n",
    "아래 예시는 Waymo 데이터 셋을 이용해 3가지 단계를 진행한다.  \n",
    "1. 커스텀 데이터 셋 준비\n",
    "2. Config 준비\n",
    "3. 커스텀 데이터로 학습, 테스트, 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 커스텀 데이터셋 준비\n",
    "MMDetection3D에서는 새로운 데이터셋을 지원하는 3가지 방법이 존재한다.\n",
    "1. 데이터 셋을 존재하는 format으로 변경\n",
    "2. 데이터 셋을 표준 format으로 변경\n",
    "3. 새로운 데이터셋을 구현  \n",
    "일반적으로 위의 두 방법을 추천한다.  \n",
    "\n",
    "  \n",
    "※ 본 글에서는 Waymo 형식을 Kitti 포맷으로 변환하는 것을 예로 든다. 다른 예로 Lyft를 nuScenes로 변환하는 것은 새로운 데이터 컨버터를 구현하는 것이, 다른 데이터 포맷으로 변환하는 것 대비 쉽다(?)  \n",
    "--> 표준 fotmat이 무엇을 말하는지는 뒤에 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. KITTI dataset format 으로 변환하기\n",
    "- Imageset은 training/validation/testing 으로 나눌 데이터 목록 txt 파일을 포함한다.\n",
    "- calib은 켈리브레이션 정보, image_2, velodyne, label_2는 각각 이미지, 라이다, 라벨 정보 포함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdetection3d\n",
    "├── mmdet3d\n",
    "├── tools\n",
    "├── configs\n",
    "├── data\n",
    "│   ├── kitti\n",
    "│   │   ├── ImageSets\n",
    "│   │   ├── testing\n",
    "│   │   │   ├── calib\n",
    "│   │   │   ├── image_2\n",
    "│   │   │   ├── velodyne\n",
    "│   │   ├── training\n",
    "│   │   │   ├── calib\n",
    "│   │   │   ├── image_2\n",
    "│   │   │   ├── label_2\n",
    "│   │   │   ├── velodyne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values    Name      Description\n",
    "----------------------------------------------------------------------------\n",
    "   1    type         Describes the type of object: 'Car', 'Van', 'Truck',\n",
    "                     'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram',\n",
    "                     'Misc' or 'DontCare'\n",
    "   1    truncated    Float from 0 (non-truncated) to 1 (truncated), where\n",
    "                     truncated refers to the object leaving image boundaries     : 이미지 경계를 벗어낫는지 유무\n",
    "   1    occluded     Integer (0,1,2,3) indicating occlusion state:\n",
    "                     0 = fully visible, 1 = partly occluded\n",
    "                     2 = largely occluded, 3 = unknown\n",
    "   1    alpha        Observation angle of object, ranging [-pi..pi]              : 관찰 각도\n",
    "   4    bbox         2D bounding box of object in the image (0-based index):\n",
    "                     contains left, top, right, bottom pixel coordinates\n",
    "   3    dimensions   3D object dimensions: height, width, length (in meters)\n",
    "   3    location     3D object location x,y,z in camera coordinates (in meters)   : 카메라 좌표계 기준 물체 위치\n",
    "   1    rotation_y   Rotation ry around Y-axis in camera coordinates [-pi..pi]\n",
    "   1    score        Only for results: Float, indicating confidence in\n",
    "                     detection, needed for p/r curves, higher is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Waymo 데이터셋 다운 후에 입력 데이터와 라벨을 KITTI 형식으로 바꿔야 한다.\n",
    "- 다음 KittiDataset을 상속한 WaymoDataset을 구현하여 학습하고, KittiMetric을 상속한 WaymoMetric을 구현하여 평가 가능하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특별히 mm3d에서는, Waymo를 KITTI 포맷으로 변환하는 컨버터를 구현해 놓았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. standard format dataset 으로 변환하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waymo Dataset(CAM-Lidar)\n",
    "- 10Hz 즉, 360도 스캔에 0.1sec가 걸린다. Lidar, 카메라 등 모든 데이터 수집 빈도가 동일하다. [issue](https://github.com/waymo-research/waymo-open-dataset/issues/102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waymo Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/open-mmlab/mmdetection3d/blob/dev-1.x/tools/dataset_converters/waymo_converter.py\n",
    "\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "r\"\"\"Adapted from `Waymo to KITTI converter\n",
    "    <https://github.com/caizhongang/waymo_kitti_converter>`_.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    from waymo_open_dataset import dataset_pb2\n",
    "except ImportError:\n",
    "    raise ImportError('Please run \"pip install waymo-open-dataset-tf-2-6-0\" '\n",
    "                      '>1.4.5 to install the official devkit first.')\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import exists, join\n",
    "\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from waymo_open_dataset.utils import range_image_utils, transform_utils\n",
    "from waymo_open_dataset.utils.frame_utils import \\\n",
    "    parse_range_image_and_camera_projection\n",
    "\n",
    "\n",
    "class Waymo2KITTI(object):\n",
    "    \"\"\"Waymo to KITTI converter.\n",
    "\n",
    "    This class serves as the converter to change the waymo raw data to KITTI\n",
    "    format.\n",
    "\n",
    "    Args:\n",
    "        load_dir (str): Directory to load waymo raw data.\n",
    "        save_dir (str): Directory to save data in KITTI format.\n",
    "        prefix (str): Prefix of filename. In general, 0 for training, 1 for\n",
    "            validation and 2 for testing.\n",
    "        workers (int, optional): Number of workers for the parallel process.\n",
    "            Defaults to 64.\n",
    "        test_mode (bool, optional): Whether in the test_mode.\n",
    "            Defaults to False.\n",
    "        save_cam_sync_labels (bool, optional): Whether to save cam sync labels. 카메라 싱크 라벨??\n",
    "            Defaults to True.\n",
    "    \"\"\"    \n",
    "    def __init__(self,\n",
    "                 load_dir,\n",
    "                 save_dir, \n",
    "                 prefix,\n",
    "                 workers=64,\n",
    "                 test_mode=False,\n",
    "                 save_cam_sync_labels=True):\n",
    "        self.filter_empty_3dboxes = True\n",
    "        self.filter_no_label_zone_points = True\n",
    "\n",
    "        self.selected_waymo_classes = ['VEHICLE', 'PEDESTRIAN', 'CYCLIST']\n",
    "\n",
    "        # Only data collected in specific locations will be converted\n",
    "        # If set None, this filter is disabled\n",
    "        # Available options: location_sf (main dataset)\n",
    "        self.selected_waymo_locations = None # ??<------------------\n",
    "        self.save_track_id = False\n",
    "\n",
    "        # turn on eager execution for older tensorflow versions\n",
    "        if int(tf.__version__.split('.')[0]) < 2:\n",
    "            tf.enable_eager_execution()\n",
    "\n",
    "        # keep the order defined by the official protocol\n",
    "        self.cam_list = [\n",
    "            '_FRONT',\n",
    "            '_FRONT_LEFT',\n",
    "            '_FRONT_RIGHT',\n",
    "            '_SIDE_LEFT',\n",
    "            '_SIDE_RIGHT',\n",
    "        ]\n",
    "\n",
    "        self.lidar_list = ['TOP', 'FRONT', 'SIDE_LEFT', 'SIDE_RIGHT', 'REAR']\n",
    "        self.type_list = [\n",
    "            'UNKNOWN', 'VEHICLE', 'PEDESTRIAN', 'SIGN', 'CYCLIST'\n",
    "        ]\n",
    "        self.waymo_to_kitti_class_map = {\n",
    "            'UNKNOWN': 'DontCare',\n",
    "            'PEDESTRIAN': 'Pedestrian',\n",
    "            'VEHICLE': 'Car',\n",
    "            'CYCLIST': 'Cyclist',\n",
    "            'SIGN': 'Sign'  # not in kitti\n",
    "        }\n",
    "\n",
    "        self.load_dir = load_dir\n",
    "        self.save_dir = save_dir\n",
    "        self.prefix = prefix\n",
    "        self.workers = int(workers)\n",
    "        self.test_mode = test_mode\n",
    "        self.save_cam_sync_labels = save_cam_sync_labels\n",
    "\n",
    "        self.tfrecord_pathnames = sorted(\n",
    "            glob(join(self.load_dir, '*.tfrecord'))\n",
    "        )\n",
    "\n",
    "        self.label_save_dir = f'{self.save_dir}/label_'\n",
    "        self.label_all_save_dir = f'{self.save_dir}/label_all' # ??<------------------\n",
    "        self.image_save_dir = f'{self.save_dir}/image_'\n",
    "        self.calib_save_dir = f'{self.save_dir}/calib'\n",
    "        self.point_cloud_save_dir = f'{self.save_dir}/velodyne'\n",
    "        self.pose_save_dir = f'{self.save_dir}/pose'\n",
    "        self.timestamp_save_dir = f'{self.save_dir}/timestamp'\n",
    "\n",
    "        self.create_folder()\n",
    "\n",
    "    def convert(self):\n",
    "        \"\"\"Convert action.\"\"\"\n",
    "        print('Start converting ...')\n",
    "        mmengine.track_parallel_progress(self.convert_one, range(len(self)), self.workers)\n",
    "        print('\\nFinished ...')\n",
    "\n",
    "    def convert_one(self, file_idx):\n",
    "        \"\"\"Convert action for single file.\n",
    "\n",
    "        Args:\n",
    "            file_idx (int): Index of the file to be converted.\n",
    "        \"\"\"\n",
    "        pathname = self.tfrecord_pathnames[file_idx]\n",
    "        dataset = tf.data.TFRecordDataset(pathname, compression_type='')\n",
    "\n",
    "        for frame_idx, data in enumerate(dataset):\n",
    "\n",
    "            frame = dataset_pb2.Frame()\n",
    "            frame.ParseFromString(bytearray(data.numpy()))\n",
    "            if (self.selected_waymo_locations is not None\n",
    "                    and frame.context.stats.location\n",
    "                    not in self.selected_waymo_locations):\n",
    "                continue\n",
    "\n",
    "            self.save_image(frame, file_idx, frame_idx)\n",
    "            self.save_calib(frame, file_idx, frame_idx)\n",
    "            self.save_lidar(frame, file_idx, frame_idx)\n",
    "            self.save_pose(frame, file_idx, frame_idx)\n",
    "            self.save_timestamp(frame, file_idx, frame_idx)\n",
    "\n",
    "            if not self.test_mode:\n",
    "                # TODO save the depth image for waymo challenge solution.\n",
    "                self.save_label(frame, file_idx, frame_idx)\n",
    "                if self.save_cam_sync_labels:\n",
    "                    self.save_label(frame, file_idx, frame_idx, cam_sync=True) # cam 동기화 라벨도 같이 저장??\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of the filename list.\"\"\"\n",
    "        return len(self.tfrecord_pathnames)\n",
    "\n",
    "    def save_image(self, frame, file_idx, frame_idx):\n",
    "        \"\"\"Parse and save the images in jpg format.\n",
    "\n",
    "        Args:\n",
    "            frame (:obj:`Frame`): Open dataset frame proto.\n",
    "            file_idx (int): Current file index.\n",
    "            frame_idx (int): Current frame index.\n",
    "        \"\"\"\n",
    "        for img in frame.images:\n",
    "            img_path = f'{self.image_save_dir}{str(img.name - 1)}/' + \\\n",
    "                f'{self.prefix}{str(file_idx).zfill(3)}' + \\\n",
    "                f'{str(frame_idx).zfill(3)}.jpg'\n",
    "            with open(img_path, 'wb') as fp:\n",
    "                fp.write(img.image)\n",
    "\n",
    "\n",
    "    def cart_to_homo(self, mat):\n",
    "        \"\"\"Convert transformation matrix in Cartesian coordinates to\n",
    "        homogeneous format.\n",
    "\n",
    "        Args:\n",
    "            mat (np.ndarray): Transformation matrix in Cartesian.\n",
    "                The input matrix shape is 3x3 or 3x4.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Transformation matrix in homogeneous format.\n",
    "                The matrix shape is 4x4.\n",
    "        \"\"\"\n",
    "        ret = np.eye(4)\n",
    "        if mat.shape == (3, 3):\n",
    "            ret[:3, :3] = mat\n",
    "        elif mat.shape == (3, 4):\n",
    "            ret[:3, :] = mat\n",
    "        else:\n",
    "            raise ValueError(mat.shape)\n",
    "        return ret\n",
    "        \n",
    "def create_ImageSets_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('mm3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d69b847d396095f32f676329057412de0235e6809d7fbe768ce2e81f9c069d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
