{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Splitting  하기\n",
    "<목차>\n",
    "1. RecursiveCharacterTextSplitter 과 CharacterTextSplitter\n",
    "2. RecursiveCharacterTextSplitter 상세\n",
    "   - text_splitter.split_documents(pages)\n",
    "   - 실 생활 예제(Text Splitter)\n",
    "3. Notion_db 분할(text_splitter.split_documents(notion_db))\n",
    "4. Token splitting\n",
    "5. Context aware splitting\n",
    "   - 실 생활 예제(Context aware splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<요약>\n",
    "- RecursiveCharacterTextSplitter는 재귀적으로, CharacterTextSplitter는 단순 문자열를 분할하는 것으로 보인다.\n",
    "- 문서를 청킹하는 경우가 실생활에서 더 많기 때문에 RecursiveCharacterTextSplitter 함수 활용을 더 많이 하길 권장\n",
    "  - 아래의 메소드가 존재하며 실행활에서 문서를 로드하는 경우가 많기 때문에 split_documents()를 더 많이 활용하도록 한다\n",
    "  - chunk_size, separator, chunk_overlap 순으로 최적화하여 활용하는 것이 중요한 것으로 보인다.  \n",
    "   \n",
    "create_documents(): 텍스트 리스트로 부터 도큐먼트 생성  \n",
    "split_documents(): 도큐먼트 분할  \n",
    "split_text(): 문자열 분할  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<심화>\n",
    "- https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "- https://python.langchain.com/docs/integrations/document_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RecursiveCharacterTextSplitter 과 CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "# 메소드\n",
    "# create_documents(): 텍스트 리스트로 부터 도큐먼트 생성\n",
    "# split_documents(): 도큐먼트 분할\n",
    "# split_text(): 문자열 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2) # chunk_overlap 개의 text가 overlap 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3) # 공백 포함해서 chunk_size 단위로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m n o p q r s t u v w x y z']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator = ' ' # \n",
    ")\n",
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. RecursiveCharacterTextSplitter 상세\n",
    "- RecursiveCharacterTextSplitter가 일반 문서 분할에 추천된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\"\n",
    "print(len(some_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(c_splitter.split_text(some_text)))\n",
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(r_splitter.split_text(some_text)))\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\",\n",
       " '. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns',\n",
       " '. Carriage returns are the \"backslash n\" you see embedded in this string',\n",
       " '. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "print(len(r_splitter.split_text(some_text)))\n",
    "r_splitter.split_text(some_text) # 분할 시 마침표(.)가 어색하게 분할되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\",\n",
       " 'For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns.',\n",
       " 'Carriage returns are the \"backslash n\" you see embedded in this string.',\n",
       " 'Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "print(len(r_splitter.split_text(some_text)))\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실 생활 예제(Text Splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(pages):  575\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "filename = './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf'\n",
    "loader = PyPDFLoader(filename)\n",
    "pages = loader.load()\n",
    "print('len(pages): ', len(pages)) # <class 'langchain.schema.document.Document'> 의 리스트\n",
    "pages_d = pages[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(docs):  2\n",
      "len(pages_d):  1\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.split_documents([pages_d])\n",
    "print('len(docs): ', len(docs))\n",
    "print('len(pages_d): ', len([pages_d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "록 하십시오.\n",
      "5. '찰칵' 소리가 날 때까지 버클에 밀어 넣으\n",
      "십시오.\n",
      "\n",
      "2. 안전벨트의 어깨띠가 어깨와 가슴을 지나\n",
      "도록 하십시오.\n",
      "3. 안전벨트가 꼬이거나 짓눌리지 않게 하십\n",
      "시오.\n",
      "4. 안전벨트의 골반띠가 골반을 부드럽게 지\n",
      "나도록 하십시오.\n",
      "5. '찰칵' 소리가 날 때까지 버클에 밀어 넣으\n",
      "십시오.\n",
      "탑승자 전원 안전벨트를 착용하십시오.\n",
      "•3점식 안전벨트를 착용할 수 없는 어린이\n",
      "의 경우 뒷좌석에 어린이용 보조 좌석을\n",
      "장착해 앉히십시오.\n",
      "RS4_G90_KO.book  Page 4\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[-40:])\n",
    "print()\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-4안전 및 주의 사항\n",
      "올바른 운전 자세\n",
      "올바른 운전 자세가 되도록 운전석과 스티어\n",
      "링 휠을 조절하십시오.\n",
      "바람직한 운전 자세는 좌석에 깊숙이 앉아\n",
      "브레이크 페달을 끝까지 밟았을 때 무릎이\n",
      "약간 굽혀지고, 손목이 스티어링 휠의 가장\n",
      "먼 곳에 닿아야 합니다. 또한, 헤드레스트의\n",
      "높이가 조절되는 차량인 경우는 운전자의 귀\n",
      "상단이 헤드레스트 중심에 올 수 있도록 헤\n",
      "드레스트를 조절하십시오.\n",
      "좌석, 스티어링 휠, 미러 조\n",
      "정\n",
      "•좌석, 스티어링 휠, 미러는 출발 전에 조\n",
      "절하시고 주행 중에 절대로 조작하지 마\n",
      "십시오.\n",
      "•내·외측의 미러를 조정하여, 충분한 시\n",
      "야를 확보하십시오.\n",
      "•모든 게이지 및 경고등을 확인하십시오.\n",
      "•주차 브레이크를 풀고 브레이크 경고등이\n",
      "꺼지는지 확인하십시오.\n",
      "•차 주위에 사람이나 물체 등이 없는지 확\n",
      "인하십시오.\n",
      "҃Ҋ\n",
      " \n",
      "•운전할 때 하이힐 등 운전하기 불편한 신\n",
      "발을 신지 마십시오. 가속 페달, 브레이크\n",
      "페달 등의 조작능력이 저하되어 사고의 원\n",
      "인이 됩니다.\n",
      "•주차 브레이크를 풀 때에는 차량이 움직일\n",
      "수 있으므로 반드시 브레이크 페달을 확실\n",
      "히 밟으십시오.\n",
      " 운전석 주변 점검\n",
      "•운전석 주변은 항상 깨끗하게 유지하십시\n",
      "오. 빈 깡통 등이 페달 밑으로 굴러 들어갈\n",
      "경우 페달 조작이 불가능하게 되어 매우\n",
      "위험합니다.\n",
      "•바닥 매트는 페달의 움직임을 방해하지 않\n",
      "는 것으로 너무 두껍지 않으면서 바닥에\n",
      "고정되는 제품이어야 합니다.\n",
      "•차 안에는 화물을 좌석 높이 이상으로 적\n",
      "재하지 마십시오.\n",
      "안전벨트 착용\n",
      "ORS021004\n",
      "모든 좌석의 탑승자들은 가까운 거리라도주행 전에 반드시 안전벨트를 착용하십시오.\n",
      "1. 엉덩이를 좌석 가장 안쪽으로 넣고 등을\n",
      "등받이에 기대어 앉으십시오. 등을 구부리\n",
      "거나 좌석 끝에 걸터앉지 마십시오. \n",
      "2. 안전벨트의 어깨띠가 어깨와 가슴을 지나\n",
      "도록 하십시오.\n",
      "3. 안전벨트가 꼬이거나 짓눌리지 않게 하십\n",
      "시오.\n",
      "4. 안전벨트의 골반띠가 골반을 부드럽게 지\n",
      "나도록 하십시오.\n",
      "5. '찰칵' 소리가 날 때까지 버클에 밀어 넣으\n",
      "십시오.\n",
      "탑승자 전원 안전벨트를 착용하십시오.\n",
      "•3점식 안전벨트를 착용할 수 없는 어린이\n",
      "의 경우 뒷좌석에 어린이용 보조 좌석을\n",
      "장착해 앉히십시오.\n",
      "RS4_G90_KO.book  Page 4  \n"
     ]
    }
   ],
   "source": [
    "print(pages_d.page_content) # 전체 다 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(docs):  2\n",
      "len(pages_d):  1\n"
     ]
    }
   ],
   "source": [
    "text_splitter_r = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "docs = text_splitter_r.split_documents([pages_d])\n",
    "print('len(docs): ', len(docs))\n",
    "print('len(pages_d): ', len([pages_d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-4안전 및 주의 사항\n",
      "올바른 운전 자세\n",
      "올바른 운전 자세가 되도록 운전석과 스티어\n",
      "링 휠을 조절하십시오.\n",
      "바람직한 운전 자세는 좌석에 깊숙이 앉아\n",
      "브레이크 페달을 끝까지 밟았을 때 무릎이\n",
      "약간 굽혀지고, 손목이 스티어링 휠의 가장\n",
      "먼 곳에 닿아야 합니다. 또한, 헤드레스트의\n",
      "높이가 조절되는 차량인 경우는 운전자의 귀\n",
      "상단이 헤드레스트 중심에 올 수 있도록 헤\n",
      "드레스트를 조절하십시오.\n",
      "좌석, 스티어링 휠, 미러 조\n",
      "정\n",
      "•좌석, 스티어링 휠, 미러는 출발 전에 조\n",
      "절하시고 주행 중에 절대로 조작하지 마\n",
      "십시오.\n",
      "•내·외측의 미러를 조정하여, 충분한 시\n",
      "야를 확보하십시오.\n",
      "•모든 게이지 및 경고등을 확인하십시오.\n",
      "•주차 브레이크를 풀고 브레이크 경고등이\n",
      "꺼지는지 확인하십시오.\n",
      "•차 주위에 사람이나 물체 등이 없는지 확\n",
      "인하십시오.\n",
      "҃Ҋ\n",
      " \n",
      "•운전할 때 하이힐 등 운전하기 불편한 신\n",
      "발을 신지 마십시오. 가속 페달, 브레이크\n",
      "페달 등의 조작능력이 저하되어 사고의 원\n",
      "인이 됩니다.\n",
      "•주차 브레이크를 풀 때에는 차량이 움직일\n",
      "수 있으므로 반드시 브레이크 페달을 확실\n",
      "히 밟으십시오.\n",
      " 운전석 주변 점검\n",
      "•운전석 주변은 항상 깨끗하게 유지하십시\n",
      "오. 빈 깡통 등이 페달 밑으로 굴러 들어갈\n",
      "경우 페달 조작이 불가능하게 되어 매우\n",
      "위험합니다.\n",
      "•바닥 매트는 페달의 움직임을 방해하지 않\n",
      "는 것으로 너무 두껍지 않으면서 바닥에\n",
      "고정되는 제품이어야 합니다.\n",
      "•차 안에는 화물을 좌석 높이 이상으로 적\n",
      "재하지 마십시오.\n",
      "안전벨트 착용\n",
      "ORS021004\n",
      "모든 좌석의 탑승자들은 가까운 거리라도주행 전에 반드시 안전벨트를 착용하십시오.\n",
      "1. 엉덩이를 좌석 가장 안쪽으로 넣고 등을\n",
      "등받이에 기대어 앉으십시오. 등을 구부리\n",
      "거나 좌석 끝에 걸터앉지 마십시오. \n",
      "2. 안전벨트의 어깨띠가 어깨와 가슴을 지나\n",
      "도록 하십시오.\n",
      "3. 안전벨트가 꼬이거나 짓눌리지 않게 하십\n",
      "시오.\n",
      "4. 안전벨트의 골반띠가 골반을 부드럽게 지\n",
      "나도록 하십시오.\n",
      "5.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "또한, 헤드레스트의\n",
      "높이가 조절되는 차량인 경우는 운전자의 귀\n",
      "상단이 헤드레스트 중심에 올 수 있도록 헤\n",
      "드레스트를 조절하십시오.\n",
      "좌석, 스티어링 휠, 미러 조\n",
      "정\n",
      "•좌석, 스티어링 휠, 미러는 출발 전에 조\n",
      "절하시고 주행 중에 절대로 조작하지 마\n",
      "십시오.\n",
      "•내·외측의\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Notion_db 분할(text_splitter.split_documents(notion_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "notion_db = loader.load()\n",
    "\n",
    "docs = text_splitter.split_documents(notion_db)\n",
    "\n",
    "print(len(notion_db))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Token splitting\n",
    "- LLM은 토큰에 지정된 Context Windows가 있는 경우가 많기 때문에 유용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents([pages_d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='2-4안전 �', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='�� 주의 사�', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='�\\n올바�', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='� 운전 자', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='세\\n올바', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='른 운전 �', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='��세가 �', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='�도록 운', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='전석과 �', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24}),\n",
       " Document(page_content='��티어\\n�', metadata={'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 24})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[:10] # 토큰으로 분할하니 난리다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './[국문 G90 2023] genesis-g90-manual-kor-230601.pdf', 'page': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Context aware splitting\n",
    "- 청킹은 공통 맥락을 가진 텍스트를 함께 유지하는 것을 목표로 한다.\n",
    "- 텍스트 분할에서는 관련 텍스트를 함께 유지하기 위해 `문장`이나 `기타 구분 기호`를 사용하는 경우가 많지만, \n",
    "  많은 문서(예: Markdown)에는 분할에 명시적으로 사용할 수 있는 구조(헤더)가 있습니다.\n",
    "--> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_document = \"\"\"\n",
    "# Title\\n\\n \\\n",
    "\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n \n",
    "Hi this is Joe\\n\\n \\\n",
    "\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n \n",
    "\n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실 생활 예시(Context aware splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()\n",
    "txt = ' '.join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_header_splits = markdown_splitter.split_text(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='### Authors  \\nAndrew Brock  \\nSoham De  \\nSamuel L. Smith  \\nKaren Simonyan  \\nDeepMind  \\n### Prerequisites  \\n1. Batch Normalization  \\n[https://arxiv.org/pdf/1502.03167.pdf](https://arxiv.org/pdf/1502.03167.pdf)  \\n2. Brock et al. 2021. Characterizing Signal Propagation to Close the Performance Gap in Unnormalized ResNets ([https://arxiv.org/pdf/2101.08692.pdf](https://arxiv.org/pdf/2101.08692.pdf))\\n- 상세 내용\\n1. **Contribution**\\n- forward pass의 시그널 전파를 시각화하는 분석 도구 제안 (SPP, Signal Propagation Plot)\\n- BatchNorm 레이어 없이 높은 성능을 발휘하는 ResNet 설계  \\n2. **주제 논문과의 공통점 & 차이점**\\n- 공통점\\n- Batch Normalization의 문제를 지적 - 학습 데이터 간의 독립성 훼손, 계산량 및 메모리 과부하, 예상치 못한 버그 유발, batch size에 따라 정확도 달라짐, 학습과 추론 간의 갭\\n- Batch Normalization의 장점 나열 - loss surface를 스무스하게 해줌, 높은 learning rate로 학습 가능, 미니배치마다 다른 statistics로 인한 정규화 효과, skip connection 사용시 forward pass의 신호 전파가 잘 이루어지도록 해줌\\n- BatchNorm 사용하지 않음\\n- 차이점:\\n- BatchNorm의 역할을 대신하는 Scaled Weight Standardization 제안\\n- 근데 SOTA보다 못함.. 그래서 추후에 (1달 뒤에) Adaptive Gradient Clipping 제안  \\n3. **SPP (Signal Propagation Plot)**\\n- SPP는 forward pass의 시그널 전파만을 시각화하지만, 이전 연구들에 의하면 forward pass의 신호 전파가 제대로 이루어지는 한 backward pass의 신호가 explode하거나 vanish하지 않음. 따라서 뉴럴넷을 설계하는 데 유용하게 활용 가능  \\n![High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/2021-03-09_221623.png](High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/2021-03-09_221623.png)  \\n- BatchNorm, ReLU activation, He initialization 사용하여 BN-ReLU-Conv (일반적으로 사용되는 순서) 및 ReLU-BN-Conv의 forward pass 전파를 시각화  \\n![High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/2021-03-09_222814.png](High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/2021-03-09_222814.png)  \\n- Average Channel Variance의 경우, 각 stage의 depth가 깊어질수록 선형적으로 증가하다가 각 trainsition block에서 1로 초기화됨\\n- 용어 정리 - transition block? stage?  \\n![High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/2021-03-11_215635.png](High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/2021-03-11_215635.png)  \\n4. **Scaled Weight Standardization**\\n3. Gradient Clipping\\n- 상세내용  \\n논문 링크: [https://arxiv.org/pdf/1211.5063.pdf](https://arxiv.org/pdf/1211.5063.pdf)  \\n- 해결하고자 했던 문제  \\nRNN 계열의 모델 등 딥러닝 모델이 가지는 vanishing, exploding gradient를 극복  \\n- 제안한 해결 방법  \\n일정 threshold를 정하고, gradient의  norm이 그 threshold 보다 크면, 모델의 gradient를 threshold와 곱하고, norm으로 나눔  \\n![High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/Untitled.png](High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/Untitled.png)  \\n- 놓치고 있던 점 (김병현)\\n- Gradient의 norm의 계산이 모든 레이어의 gradient로 계산된 값, global 한 값이었다는 점을 제대로 이해하지 못하고 있었음\\n—> Adaptive gradient clipping과 다른 점\\n그래서 AGC보다 GC가 더 큰 threshold로 clipping을 하는 것으로 판단됨\\n- 따라서 Batch-Norm을 대체하기 위한 시도로 제안된 AGC는 레이어 단위로 gradient를 clipping 해줄 필요가 있었던 것으로 보임\\n- Pseudo 코드의 Pseudo 코드(?)  \\n```python\\n1. 레이어 전체의 gradient에 대하여 norm을 구함 (보통 L2 Norm)\\n2. gradient의 norm 이 threshold를 넘는지 넘지 않는지 판단  \\n3-1. (넘는 경우)\\n(Pytorch나 Tensorflow 에서는 Iterable하게\\n각 레이어의 gradient에 접근할 수 있으므로)\\n각 레이어의 gradient에 for loop으로 접근하여 threshold를 곱하고 norm으로 나눠줌  \\n2. (안넘는경우)\\n아무 동작 안함  \\n```  \\n- 효고  \\n점선은 gradient가 rescale 됬을 때 나타나는 gradient의 방향을 나타냄  \\n![High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/Untitled%201.png](High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/Untitled%201.png)  \\n4. Contrastive Learning\\n- 내용\\n- Pairwise Loss / Triplet Loss  \\n![High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/Untitled%202.png](High-Performance%20Large-Scale%20Image%20Recognition%20Wit%208519dcd750294c8aa6672373d3df65ad/Untitled%202.png)  \\n- 위 그림은 Triplet Loss 설명. Pairwise Loss는 Positive와 Negative만 존재하는 Loss라고 볼 수 있음\\n- 일반적인 Loss는 단일 Image만 가지고 Loss를 계산하여 Parameter를 Update.\\n- Pair-Wise Loss는 2개, Triplet은 3개, Quadruplet Loss는 4개\\n- Pair Wise Loss는 Anchor, Positive, Negative, 즉 Positive 2개와 Negative 1개를 추출차여 유클리디안 거리를 조절하는 방식\\n- Contrastive Learning은 Pairwise Loss와 동일하게 작동하는 방법\\n- SimCLR\\n- Constrastive Learning을 사용한 Self-Supervised Learning 논문\\n- Negative Sample을 사용하지 않고, Batch Size를 크게 잡아서 Input 이미지를 제외한 나머지 Batch들이 Negative이라고 가정 (Batch Size를 키워서 Negative Sample이 있을 가능성을 높임)\\n- 큰 Batch가 사용되므로 (8192개) Multi GPU를 사용해야 하고, 그 과정에서 Mini-batch 단위로 평균과 분산을 다 계산해서 합침 (GPU 끼리의 정보이동 및 Aggregation 과정이 필요)\\n- 일반적인 BN은 Activation Function전에 적용하는데, 위 논문은 Activation 이후에 적용함\\n- Batch와 관련된 참고 논문 : Understanding self-supervised and contrastive learning with \"Bootstrap Your Own Latent\" (BYOL)([요약](https://generallyintelligent.ai/understanding-self-supervised-contrastive-learning.html))\\n- 리뷰하고 있는 논문에서 언급되어 있지 않은걸 보아 위 논문의 내용이 정확하게 일치 하지 않을 수 있지만 유사한 내용이 있음\\n- 결론적으로, Contrastive Learning 방법들(MoCo, SimCLR)은 Negative Sample들을 사용하지 않는데, BN이 Contrastive Learning 방식을 암시적으로도입해준다.  (실험을 통해 증명함)\\n- 결론중에서, BN을 사용하면 Network Output은 Pure Function을 학습하지 않는다고 한다. 때문에 BN을 피하는 것이 좋다는 언급이 있다.\\n- (의견) Pure한 Function을 학습하지 않는다는 뜻은. BN을 통해서 네트워크가 학습한 어떠한 수식의 원형을 알 수 없다는 것을 의미하는 것 같음. Mean shift 등의 계산으로 Input에 어떠한 변형이 항상 가해지고, 그 변형들은 전체 Dataset에 따라 다르기 때문에 Input에 대한 Output의 관계가 항상 일정하지 않음.  \\n5. BN과 관련된 참고[자료](https://www.alexirpan.com/2017/04/26/perils-batch-norm.html) : BN 사용에 대한 불합리성', metadata={'Header 1': 'High-Performance Large-Scale Image Recognition Without Normalization'})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
