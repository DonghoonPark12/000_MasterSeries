{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "##### 사전 지식\n",
    "- [파이썬 멀티 프로세싱](https://python.flowdas.com/library/multiprocessing.html#module-multiprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
=======
>>>>>>> ddb03d68762080ad3ff4e1fbbc1c66deba0e631e
    "#### [Single- and Multi-process Data Loading](https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading)\n",
    "- DataLoader는 싱글 프로세스를 데이터 로딩시 디폴트로 사용한다.\n",
    "- 파이썬 프로세스 내에서,  [Global Interpreter Lock (GIL)](https://wiki.python.org/moin/GlobalInterpreterLock)은 스레드 간의 파이썬 코드가 완전히 병렬화 되는 것을 막는다.\n",
    "- 데이터 로딩시 계산 코드 수행 막는 것을 방지 하기 위해서(*), 파이토치는 num_workers 인자를 도입하여 다중 프로세스 데이터 로딩을 수행할 수 있게 한다.  \n",
    "  \n",
    "(*) '프로세스 수행 중 데이터 로딩이 병목의 원인이 되지 않기 위해서'로 이해하였다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single-process data loading (default) (num_worker=0)\n",
    "- 해당 모드에서는 DataLoader가 초기화 되었던 프로세스와 동일 프로세스에서 데이터 Fetching을 수행한다. 따라서, 데이터 로딩이 Computing을 막을 수도 있다(*). 그러나 해당 모드는 프로세스들 간의 데이터를 공유하는 경우에 자원(e.g. Shared Memory, File Discriptor)이 제한되어 있을 때 선호될 수 있다.  \n",
    "- 혹은, 전체 데이터셋 사이즈가 작고, 메모리에 전부 로드 될 수 있을때 선호될 수 있다.\n",
    "- 또한, Single-process 로딩은 가독성이 상대적으로 나은 에러를 보이기 때문에 디버깅 하기에 편리하다\n",
    "\n",
    "(*) 왜냐하면, 데이터로딩과 그 외 작업을 수행하는 프로세스를 다르게 두면 병렬로 수행할 수 있으나, 로딩과 그 외 작업을 하나의 프로세스에서 수행하면 데이터 로딩이 병목을 일으킬 수 있기 때문."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-process data loading\n",
    "\n",
    "- num_workers 인수를 양수로 두면, 인수로 지정한 갯수 만큼의 다중 프로세스 데이터로딩을 수행한다.  \n",
    "- 해당 모드에서 DataLoader 반복자가 생성될 때 마다 (즉, enumerate(dataloader)을 호출할 때 마다) num_workers 갯수 만큼의 worker 프로세스 들이 생성된다 (반복자를 호출할 때 마다 프로세스가 생성되어 데이터를 가져온다??!!)\n",
    "- 이때, dataset, collate_fn, worker_init_fn 인자가 각 worker에 넘겨져서, 데이터를 fetch 하고 초기화를 수행한다.  \n",
    "- 이 말인 즉슨 내부 IO로 각 프로세스가 데이터 접근을 동시에 하여, collate_fn 함수로 변환을 수행한다는 얘기.\n",
    "\n",
    "Warning  \n",
    "- 몇몇 반복이 있은 후에 *로더 worker 프로세스*는, *worker 프로세스에서 접근하는 부모 프로세스의 모든 파이썬 객체에 대해* 부모 프로세스와 동일한 양의 CPU 메모리를 소비한다(*). \n",
    "- 이는 데이터가 많이 크거나, 많은 worker가 있는 경우(전체 메모리 사용량 : number of workers * 부모 프로세스 사이즈 크기) 문제가 될 수 있다. \n",
    "- 위의 문제에 대한 간단한 해결책은 파이썬 객체를 Pandas, Numpy, PyArror 객체와 같이 non-refcounted 표현으로 바꾸는 것이다([관련 이슈](https://github.com/pytorch/pytorch/issues/13246#issuecomment-905703662))\n",
    "\n",
    "\n",
    "(*) 자식 로더 프로세스도 부모 프로세스 만큼 CPU를 소모한다(?) 그래서, '전체 메모리 사용량 = number of workers x 부모 프로세스 사이즈 크기'로 표현한 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [torch.utils.data.get_worker_info()](https://pytorch.org/docs/stable/data.html#torch.utils.data.get_worker_info)는 worker 프로세스의 아래의 정보를 제공한다.\n",
    "  - worker id\n",
    "  - (가져오는) 데이터 복사본\n",
    "  - 초기 seed   \n",
    "- 메인 프로세스에서는 None을 반환한다.\n",
    "- 사용자는 데이터 코드에서 worker_init_fn를 사용하여 데이터 셋 복사본을 개별 구성하고, 코드가 worker 프로세스에서 실행중인지 여부를 파악할 수 있다. 특히나 데이터를 공유할 때 유용하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 맵 스타일 데이터 셋이서는 메인 프로세스가 *sampler*를 이용해서 인덱스를 생성하고, workers에 보낸다. 따라서, 모든 무작위 셔플은 메인 프로세스에서 실행된다.\n",
<<<<<<< HEAD
    "- **반복자 스타일 데이터 셋이서는 각 worker 프로세스가 dataset 객체 복사본을 얻기 때문에**, naive 한 다중 프로세스 로딩은 데이터 중복을 일으킬 수 있다.\n",
    "- [torch.utils.data.get_worker_info()](https://pytorch.org/docs/stable/data.html#torch.utils.data.get_worker_info)와 worker_init_fn을 이용하여 각 복사본을 독립적으로 구성할 수 있다. \n",
    "- 유사한 이유로, 멀티 프로세스 로딩에서는 drop_last 인자가 각 worker의 반복자 스타일 데이터 셋 복사본 의 non-full(꽉 차지 않은) 데이터 셋을 삭제한다."
=======
    "- 반복자 스타일 데이터 셋이서는 각 worker 프로세스가 dataset 객체 복사본을 얻기 때문에, naive 한 다중 프로세스 로딩은 데이터 중복을 일으킬 수 있다.\n",
    "- [torch.utils.data.get_worker_info()](https://pytorch.org/docs/stable/data.html#torch.utils.data.get_worker_info)와 worker_init_fn을 이용하여 각 복사본을 독립적으로 구성할 수 있다. "
>>>>>>> ddb03d68762080ad3ff4e1fbbc1c66deba0e631e
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Warning\n",
    "- 일반적으로 다중 프로세스 로딩에서 CUDA 텐서를 반환하는 것을 권장하진 않는다 [CUDA Mutiprocessing](https://pytorch.org/docs/stable/notes/multiprocessing.html#multiprocessing-cuda-note)\n",
    "- 대신에, [자동 메모리 고정](https://pytorch.org/docs/stable/data.html#memory-pinning) (pin_memory=True 설정)을 사용하여 GPU로 데이터 전송을 빠르게 하기 권장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Platform-specific behaviors\n",
    "- worker는 파이썬 멀티프로세싱에 의존하기 때문에 윈도우와 유닉스에서 다르게 동작한다.\n",
    "- 유닉스에서 fork()는 멀티프로세싱 디폴트 시작 메소드이다. 하위 worker는 복제된 주소 공간을 통해 데이터 셋 및 파이썬 인수 함수(?)에 직접 접근할 수 있다\n",
    "- 윈도우/ MacOS 에서 spawn()은 멀티프로세싱 디폴트 시작 메소드이다. spawn을 사용하면, 메인 스크립트를 실행하는 다른 인터프리터가 실행되고, pickle 직렬화를 통해 dataset, collate_fn 및 기타 인수를 수신하는 내부 worker 함수가 실행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(이하 권장하는 방식)\n",
    "- main script code를 **if __name__ == '__main__':** 블록으로 감싼다. 고로 각 worker 프로세스가 시작될 때 main script에 있는 코드가 두번 실행되지 않게 한다(그렇지 않으면 높은 확률로 에러 발생)\n",
    "- **if __name__ == '__main__':** 블록 안에 dataset, dataLoader 객체가 생성되고, worker 내에서 다시 실행될 필요가 없다.\n",
    "- 커스텀collate_fn, worker_init_fn, dataset 코드는 __main__ 밖인 탑 레벨에서 선언되게 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomness in multi-process data loading\n",
    "- 각 작업자는 base_seed + worker_id를 seed로 가진다. base_seed는 메인 프로세스의 RNG를 사용하여 생성된다.\n",
    "- 그러나, workers를 초기화 할 때, 다른 라이브러리 seeds가 중복되어 각 worker가 동일한 seed를 가지는 문제가 있기도 한다 [FAQ](https://pytorch.org/docs/stable/notes/faq.html#dataloader-workers-random-seed)\n",
    "- **worker_init_fn**에서 **torch.utils.data.get_worker_info().seed** 혹은 **torch.initial_seed()** 를 사용하여 각 worker에 대한 파이토치 seed를 접근하여 데이터 로딩 전 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Pinning\n",
    "- CPU 메모리에서 GPU 메모리로 복사는 pinned memory(page-locked)에서 수행될 때 훨씬 빠르다.\n",
    "- 데이터 로딩 경우 pin_memory=True를 DataLoader에 전달하면, 텐서가 고정된 메모리에 자동 배치되므로 GPU로의 더 빠른 데이터 전송이 가능해진다.\n",
    "- 기본 메모리 고정 로직은 Tensor와 Maps와 Tensor를 포함한 반복자만 인식한다.\n",
    "- 기본적으로 Memory Pinning이 커스텀 타입 배치를 반환하는 collate_fn을 확인하는 경우 혹은,\n",
    "- 배치의 각 요소가 커스텀 타임인 경우는 pinning logic이 해당 배치를 인식하지 못할 수도 있다.\n",
    "- 커스텀 배치 타입에서 memory_pinning이 동작하게 하기 위해서는 아래를 참고한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollate_wrapper\u001b[39m(batch):\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m SimpleCustomBatch(batch)\n\u001b[1;32m---> 15\u001b[0m inps \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mview(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class SimpleCustomBatch:\n",
    "    def __init__(self, data):\n",
    "        transposed_data = list(zip(*data))\n",
    "        self.inp = torch.stack(transposed_data[0], 0)\n",
    "        self.tgt = torch.stack(transposed_data[1], 0)\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.inp = self.inp.pin_memory()\n",
    "        self.tgt = self.tgt.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_wrapper(batch):\n",
    "    return SimpleCustomBatch(batch)\n",
    "\n",
    "inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
    "tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
    "dataset = TensorDataset(inps, tgts)\n",
    "\n",
    "loader = DataLoader(dataset, \n",
    "                    batch_size=2,\n",
    "                    collate_fn=collate_wrapper,\n",
    "                    pin_memory=True)\n",
    "\n",
    "for batch_ndx, sample in enumerate(loader):\n",
    "    print(sample.inp.is_pinned())\n",
    "    print(sample.tgt.is_pinned())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [MULTIPROCESSING BEST PRACTICES](https://pytorch.org/docs/stable/notes/multiprocessing.html)\n",
    "- torch.multiprocessing은 파이썬의 multiprocessing 모듈을 대체한다.\n",
    "- 정확히 동일한 동작을 수행하지만, 확장하여 모든 텐서가 [multiprocessing.Queue](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue)로 보내진다.\n",
    "\n",
    "Note\n",
    "- Tensor가 다른 프로세스에 전달이 되면, 텐서 데이터가 공유된다. torch.Tensor.grad가 None이 아닌 경우에도 공유된다.\n",
    "- torch.Tensor.grad가 None인 Tensor가 다른 프로세스로 전송이 되면, 표준 프로세스 구체적인 .grad Tensor가 생성된다. 그리고 해당 텐서는 모든 프로세스에서 자동으로 공유되지 않는다. \n",
    "  \n",
    "==> torch.Tensor.grad가 존재하면 프로세스 마다 텐서가 공유되고, torch.Tensor.grad=None 이면 텐서는 자동 공유되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA in multiprocessing\n",
    "- CUDA 런타임은 fork() 시작 메소드(?)를 지원하지 않는다. \n",
    "- spawn 혹은 forkserver 시작 메소드도 하위 프로세스에서 CUDA를 사용하려면 필요하다.\n",
    "\n",
    "Note  \n",
    "- 시작 메소드는 multiprocessing.get_context(...) 혹은 multiprocessing.set_start_method(...)를 통해 설정될 수 있다.\n",
    "\n",
    "- CPU 텐서와는 다르게, CUDA에서는 전송 프로세스는 수신 프로세스가 텐서의 복사본을 유지하는 한 원본 텐서를 가지고 있어야 한다(!!)\n",
    "- 내부적으로는 위와 같이 동작하나, 사용자는 프로그램을 올바르게 사용해야 한다\n",
    "- 예를 들어, 전송 프로세스는 수신 프로세스가 텐서 참조자를 가지고 있는 한 살아있어야 한다(만약 전송 프로세스가 죽으면 수신 프로세스 참조자는 데이터를 잃어 버린다)\n",
    "\n",
    "참조: https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse buffers passed through a Queue\n",
    "- 텐서를 multiprocessing.Queue로 옮기면, 공유 메모리로 이동 한다.\n",
    "-  이미 공유 메모리로 이동한 경우라면 아무 작업을 하지 않는다.\n",
    "-  단일 프로세스로 데이터를 보내는 프로세스 Pool이 있다고 하더라도, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharing CUDA tensors\n",
    "- 프로세스간 CUDA 텐서 공유는 spawn, forkserver 시작 메소드를 이용하면 가능하다.\n",
    "- CPU 텐서와는 다르게, CUDA에서는 전송 프로세스는 수신 프로세스가 텐서의 복사본을 유지하는 한 원본 텐서를 가지고 있어야 한다.\n",
    "\n",
    "Warning\n",
    "- 만약, 수신 프로세스가 특정 Signal로 인해 종료되면, 공유된 텐서는 전송 프로세스가 Running 하는 동안에 메모리에 남아 있게 된다.\n",
    "\n",
    "==> 즉, 수신 프로세스가 텐서 참조자를 가지고 있는 한 송신 프로세스는 죽으면 안되고, 수신 프로세스는 텐서를 받자 마자 릴리스해야 텐서가 가비지 처럼 메모리에 쌓이는 것을 막을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 1. 수신 프로세스는 메모리를 최대한 빨리 릴리스 한다 '''\n",
    "## Good\n",
    "x = queue.get()\n",
    "# do somethings with x\n",
    "del x\n",
    "\n",
    "## Bad\n",
    "x = queue.get()\n",
    "# do somethings with x\n",
    "# do everything else (producer have to keep x in memory)"
=======
    "- 일반적으로 다중 프로세스 로딩에서 CUDA 텐서를 반환하는 것을 권장하진 않는다[CUDA Mutiprocessing](https://pytorch.org/docs/stable/notes/multiprocessing.html#multiprocessing-cuda-note)\n",
    "- 대신에, (자동 메모리 고정)[https://pytorch.org/docs/stable/data.html#memory-pinning] (pin_memory=True 설정)을 사용하여 GPU로 데이터 전송을 빠르게 하기 권장한다."
>>>>>>> ddb03d68762080ad3ff4e1fbbc1c66deba0e631e
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('torchWin_rev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
<<<<<<< HEAD
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
=======
   "name": "python",
>>>>>>> ddb03d68762080ad3ff4e1fbbc1c66deba0e631e
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dcfd0bbc3e25ae79d1f134c08b87e3777d49169aec2e55e1b5fb8249822c085d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
